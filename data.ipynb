{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_file, schema_file):\n",
    "    col_names = []\n",
    "    col_types = []\n",
    "\n",
    "    with open(schema_file, \"r\") as f:\n",
    "        for ix, line in enumerate(f.read().strip(\"\\n\").split(\"\\n\")):\n",
    "            el = line.split(\"\\t\")\n",
    "            if len(el) != 2:\n",
    "                raise Exception(f\"Error while parsing chema file '{schema_file}' at line {ix + 1}, expected 2 values, but found {el}\")\n",
    "            \n",
    "            name, type = el\n",
    "\n",
    "            if len(name) == 0:\n",
    "                raise Exception(f\"Error while parsing chema file '{schema_file}' at line {ix + 1}, empty name\")\n",
    "            if type not in [\"str\", \"num\"]:\n",
    "                raise Exception(f\"Error while parsing chema file '{schema_file}' at line {ix + 1}, unknown type '{type}'. Possible types: 'str', 'num'\")\n",
    "\n",
    "            col_names.append(name)\n",
    "            col_types.append(type)\n",
    "    \n",
    "    data = []\n",
    "\n",
    "    with open(data_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        for ix, line in enumerate(f.read().strip(\"\\n\").split(\"\\n\")):\n",
    "            el = line.split(\"\\t\")\n",
    "\n",
    "            if len(el) != len(col_names):\n",
    "                raise Exception(f\"Error while parsing data file '{data_file}' at line {ix + 1}, expected {len(col_names)} values, but found {len(el)}\")\n",
    "            \n",
    "            entry = {}\n",
    "\n",
    "            for i in range(len(el)):\n",
    "                if col_types[i] == \"num\":\n",
    "                    try:\n",
    "                        entry[col_names[i]] = float(el[i].strip())\n",
    "                    except:\n",
    "                        entry[col_names[i]] = None\n",
    "                else:\n",
    "                    entry[col_names[i]] = el[i].strip()\n",
    "            \n",
    "            data.append(entry)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 161682 entries for year 2014\n",
      "Loaded 168939 entries for year 2015\n",
      "Loaded 137338 entries for year 2016\n",
      "Loaded 135513 entries for year 2017\n",
      "Loaded 136864 entries for year 2018\n",
      "Loaded 136091 entries for year 2019\n",
      "Loaded 155750 entries for year 2020\n",
      "Loaded 133664 entries for year 2021\n",
      "Loaded 126453 entries for year 2022\n",
      "Loaded 130522 entries for year 2023\n"
     ]
    }
   ],
   "source": [
    "schema_files = {\n",
    "    2014: \"meta/schema-dgov.txt\",\n",
    "    2015: \"meta/schema-dgov.txt\",\n",
    "    2016: \"meta/schema-dgov.txt\",\n",
    "    2017: \"meta/schema-dgov.txt\",\n",
    "    2018: \"meta/schema-dgov.txt\",\n",
    "    2019: \"meta/schema-edu-raport.txt\",\n",
    "    2020: \"meta/schema-edu-raport.txt\",\n",
    "    2021: \"meta/schema-edu-initial.txt\",\n",
    "    2022: \"meta/schema-edu-initial.txt\",\n",
    "    2023: \"meta/schema-edu-initial.txt\",\n",
    "}\n",
    "\n",
    "data = {}\n",
    "\n",
    "for year in range(2014, 2024):\n",
    "    data[year] = load_data(f\"data/bac/{year}.csv\", schema_files[year])\n",
    "    print(f\"Loaded {len(data[year])} entries for year {year}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18434\n",
      "{'nr_crt': 1.0, 'cod_siiir': '0261205195', 'nume_unitate': 'ASOCIAȚIA CREȘTINĂ DE CARITATE SAMARITEANUL - GRADINITA SAMARITEANUL AGRIȘU MARE', 'denumire': 'GRADINITA SAMARITEANUL AGRIȘU MARE', 'oras': 'AGRIŞU MARE', 'localitate': 'TÂRNOVA', 'judet': 'ARAD', 'stare_legala': 'Cu personalitate juridică', 'tip_unitate': 'Unitate de învățământ', 'administrare': 'Privată'}\n"
     ]
    }
   ],
   "source": [
    "siiir = load_data(\"meta/siiir.csv\", \"meta/siiir-schema.csv\")\n",
    "\n",
    "print(len(siiir))\n",
    "print(siiir[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7453\n",
      "{'nr_crt': 1.0, 'judet': 'Alba', 'nume_unitate': 'LICEUL TEHNOLOGIC AGRICOL \"ALEXANDRU BORZA\" CIUMBRUD', 'cod_sirues': '844547', 'clasificare_1': 'Unitate de învăţământ', 'clasificare_2': 'Grup şcolar agricol', 'clasificare_3': 'Grup şcolar', 'clasificare_4': 'Unitate de învăţământ', 'clasificare_5': 'Grup şcolar agricol'}\n"
     ]
    }
   ],
   "source": [
    "sirues = load_data(\"meta/sirues.csv\", \"meta/sirues-schema.csv\")\n",
    "\n",
    "print(len(sirues))\n",
    "print(sirues[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clear_diacritics(s):\n",
    "    mappings = [\n",
    "        ('Á', 'A'),\n",
    "        ('Â', 'A'),\n",
    "        ('É', 'E'),\n",
    "        ('Î', 'I'),\n",
    "        ('Ó', 'O'),\n",
    "        ('Ö', 'O'),\n",
    "        ('Ă', 'A'),\n",
    "        ('Ő', 'O'),\n",
    "        ('Ş', 'S'),\n",
    "        ('Ţ', 'T'),\n",
    "        ('Ș', 'S'),\n",
    "        ('Ț', 'T'),\n",
    "    ]\n",
    "    for a, b in mappings:\n",
    "        s = s.replace(a, b)\n",
    "        s = s.replace(a.lower(), b.lower())\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignored 366/161682 entries\n",
      "Ignored 281/168939 entries\n",
      "Ignored 237/137338 entries\n",
      "Ignored 185/135513 entries\n",
      "Ignored 72/136864 entries\n",
      "Found 33 unique characters for year 2014: [' ', '\"', ',', '-', '.', '1', '2', '3', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
      "Found 1496 licee for year 2014, total 1496\n",
      "Found 33 unique characters for year 2015: [' ', '\"', ',', '-', '.', '1', '2', '3', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
      "Found 1479 licee for year 2015, total 1592\n",
      "Found 33 unique characters for year 2016: [' ', '\"', ',', '-', '.', '1', '2', '3', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
      "Found 1477 licee for year 2016, total 1599\n",
      "Found 33 unique characters for year 2017: [' ', '\"', ',', '-', '.', '1', '2', '3', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
      "Found 1476 licee for year 2017, total 1607\n",
      "Found 33 unique characters for year 2018: [' ', '\"', ',', '-', '.', '1', '2', '3', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
      "Found 1457 licee for year 2018, total 1611\n",
      "Found 33 unique characters for year 2019: [' ', '\"', ',', '-', '.', '1', '2', '3', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
      "Found 1450 licee for year 2019, total 1639\n",
      "Found 33 unique characters for year 2020: [' ', '\"', ',', '-', '.', '1', '2', '3', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
      "Found 1454 licee for year 2020, total 1646\n",
      "Found 33 unique characters for year 2021: [' ', '\"', ',', '-', '.', '1', '2', '3', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
      "Found 1438 licee for year 2021, total 1649\n",
      "Found 33 unique characters for year 2022: [' ', '\"', ',', '-', '.', '1', '2', '3', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
      "Found 1439 licee for year 2022, total 1689\n",
      "Found 33 unique characters for year 2023: [' ', '\"', ',', '-', '.', '1', '2', '3', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
      "Found 1432 licee for year 2023, total 1706\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def get_county_code(county_name):\n",
    "    counties = [('AB', 'ALBA'), ('AG', 'ARGES'), ('AR', 'ARAD'), ('B', 'BUCURESTI'), ('BC', 'BACAU'), ('BH', 'BIHOR'), ('BN', 'BISTRITA'), ('BR', 'BRAILA'), ('BT', 'BOTOSANI'), ('BV', 'BRASOV'), ('BZ', 'BUZAU'), ('CJ', 'CLUJ'), ('CL', 'CALARASI'), ('CS', 'CARAS'), ('CT', 'CONSTANTA'), ('CV', 'COVASNA'), ('DB', 'DAMBOVITA'), ('DJ', 'DOLJ'), ('GJ', 'GORJ'), ('GL', 'GALATI'), ('GR', 'GIURGIU'), ('HD', 'HUNEDOARA'), ('HR', 'HARGHITA'), ('IF', 'ILFOV'), ('IL', 'IALOMITA'), ('IS', 'IASI'), ('MH', 'MEHEDINTI'), ('MM', 'MARAMURES'), ('MS', 'MURES'), ('NT', 'NEAMT'), ('OT', 'OLT'), ('PH', 'PRAHOVA'), ('SB', 'SIBIU'), ('SJ', 'SALAJ'), ('SM', 'SATU'), ('SV', 'SUCEAVA'), ('TL', 'TULCEA'), ('TM', 'TIMIS'), ('TR', 'TELEORMAN'), ('VL', 'VALCEA'), ('VN', 'VRANCEA'), ('VS', 'VASLUI')]\n",
    "    name = clear_diacritics(county_name.upper())\n",
    "\n",
    "    for code, county in counties:\n",
    "        if county in name:\n",
    "            return code\n",
    "\n",
    "    raise Exception(f\"Unknown county {name}\")\n",
    "\n",
    "def process_dot_gov(data, siiir, sirues):\n",
    "    school_name_by_siiir = {\n",
    "        el[\"cod_siiir\"]: el[\"nume_unitate\"] for el in siiir\n",
    "    }\n",
    "\n",
    "    county_by_siiir = {\n",
    "        el[\"cod_siiir\"]: get_county_code(el[\"judet\"]) for el in siiir\n",
    "    }\n",
    "\n",
    "    school_name_by_sirues = {\n",
    "        el[\"cod_sirues\"]: el[\"nume_unitate\"] for el in sirues\n",
    "    }\n",
    "\n",
    "    county_by_sirues = {\n",
    "        el[\"cod_sirues\"]: get_county_code(el[\"judet\"]) for el in sirues\n",
    "    }\n",
    "\n",
    "    ignored = 0\n",
    "\n",
    "    for el in data:\n",
    "        if el[\"siiir\"] in school_name_by_siiir:\n",
    "            el[\"liceu\"] = school_name_by_siiir[el[\"siiir\"]]\n",
    "            el[\"judet\"] = county_by_siiir[el[\"siiir\"]]\n",
    "        elif el[\"sirues\"] in school_name_by_sirues:\n",
    "            el[\"liceu\"] = school_name_by_sirues[el[\"sirues\"]]\n",
    "            el[\"judet\"] = county_by_sirues[el[\"sirues\"]]\n",
    "        else:\n",
    "            el[\"liceu\"] = None\n",
    "            el[\"judet\"] = None\n",
    "            ignored += 1\n",
    "    \n",
    "    print(f\"Ignored {ignored}/{len(data)} entries\")\n",
    "\n",
    "for year in range(2014, 2019):\n",
    "    process_dot_gov(data[year], siiir, sirues)\n",
    "\n",
    "    \n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "def canonicalize(entry) -> str:\n",
    "    liceu = entry[\"liceu\"]\n",
    "    judet = entry[\"judet\"]\n",
    "\n",
    "    if liceu is None:\n",
    "        return \"\"\n",
    "\n",
    "    liceu = liceu.replace(\"Ăˇ\", \"Á\")\n",
    "    liceu = liceu.replace(\"Ă©\", \"É\")\n",
    "    liceu = liceu.replace(\"Ĺ‘\", \"Ő\").replace(\"Ă¶\", \"Ö\").replace(\"Ăł\", \"Ó\")\n",
    "    liceu = liceu.replace(\"â€™\", \"'\").replace(\"Â€™\", \"'\")\n",
    "    liceu = liceu.replace(\"’\", \"'\").replace(\"‘\", \"'\")\n",
    "    liceu = liceu.replace(\"''\", '\"').replace(\",,\", '\"').replace(\"„\", '\"').replace(\"”\", '\"').replace(\"“\", '\"').replace('\"\"', '\"')\n",
    "    liceu = liceu.replace(\"'\", '\"')\n",
    "    if liceu.count('\"') != 0 and liceu.count('\"') != 2:\n",
    "        liceu = liceu.replace('\"', \"\")\n",
    "    liceu = liceu.replace(\"_\", \" \")\n",
    "    liceu = liceu.replace(\"Ş\", \"Ș\").replace(\"Ţ\", \"Ț\").replace(\"ş\", \"ș\").replace(\"ţ\", \"ț\")\n",
    "\n",
    "    liceu = liceu.upper()\n",
    "    \n",
    "    # forbidden = [' ', '\"', '(', ')', ',', '-', '.']\n",
    "    # for f in forbidden:\n",
    "    #     liceu = liceu.replace(f, \" \")\n",
    "\n",
    "    # 'Á', 'Â', 'É', 'Î', 'Ó', 'Ö', 'â', 'Ă', 'ă', 'Ő', 'Ş', 'ş', 'Ţ', 'ţ', 'Ș', 'ș', 'Ț', 'ț'\n",
    "    # only uppercase\n",
    "    liceu = clear_diacritics(liceu)\n",
    "    \n",
    "    liceu = re.sub(r\" +\", \" \", liceu)\n",
    "    liceu = liceu.strip()\n",
    "    \n",
    "\n",
    "    if liceu.count('\"') != 0:\n",
    "        # total 1776\n",
    "        l = liceu.split('\"')\n",
    "        x = re.sub(r\"[^A-Z]+\", \" \", l[1]).strip()\n",
    "        x = x.split(\" \")\n",
    "        x = '.'.join([el[0] for el in x[:-1]] + [x[-1]])\n",
    "        liceu = '\"'.join([l[0], x, l[2]])\n",
    "    \n",
    "    if liceu.count('\"') != 0 or liceu.count(\",\") != 0:\n",
    "        last_pos = max(liceu.rfind('\"') + 1, liceu.rfind(\",\"))\n",
    "        liceu = liceu[:last_pos] + \" \" + judet\n",
    "\n",
    "    return liceu\n",
    "\n",
    "total_licee = set()\n",
    "for year in range(2014, 2024):\n",
    "    charset = sorted(set(''.join([canonicalize(el) for el in data[year]])))\n",
    "    print(f\"Found {len(charset)} unique characters for year {year}: {charset}\")\n",
    "    licee = set([canonicalize(el) for el  in data[year]])\n",
    "    \n",
    "    # if year == 2014:\n",
    "    #     f = open(\"liceu-2014.txt\", \"w\")\n",
    "    #     for l in licee:\n",
    "    #         f.write(l + \"\\n\")\n",
    "    #     f.close()\n",
    "    # if year == 2015:\n",
    "\n",
    "    total_licee = total_licee.union(licee)\n",
    "    print(f\"Found {len(licee)} licee for year {year}, total {len(total_licee)}\")\n",
    "    # print(f\"New licee for year {year}:\")\n",
    "    # if year > 2014:\n",
    "    #     for l in licee:\n",
    "    #         if l not in total_licee:\n",
    "    #             print(l)\n",
    "\n",
    "    \n",
    "f = open(\"liceu-2014.txt\", \"w\")\n",
    "for l in licee:\n",
    "    f.write(l + \"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"output.txt\", \"w\", encoding=\"utf-8\")\n",
    "\n",
    "for liceu in total_licee:\n",
    "    # if \".\" in liceu:\n",
    "    f.write(f'{liceu}\\n')\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('MS', 'MURES') ('MM', 'MARAMURES')\n",
      "[('AB', 'ALBA'), ('AG', 'ARGES'), ('AR', 'ARAD'), ('B', 'BUCURESTI'), ('BC', 'BACAU'), ('BH', 'BIHOR'), ('BN', 'BISTRITA'), ('BR', 'BRAILA'), ('BT', 'BOTOSANI'), ('BV', 'BRASOV'), ('BZ', 'BUZAU'), ('CJ', 'CLUJ'), ('CL', 'CALARASI'), ('CS', 'CARAS'), ('CT', 'CONSTANTA'), ('CV', 'COVASNA'), ('DB', 'DAMBOVITA'), ('DJ', 'DOLJ'), ('GJ', 'GORJ'), ('GL', 'GALATI'), ('GR', 'GIURGIU'), ('HD', 'HUNEDOARA'), ('HR', 'HARGHITA'), ('IF', 'ILFOV'), ('IL', 'IALOMITA'), ('IS', 'IASI'), ('MH', 'MEHEDINTI'), ('MM', 'MARAMURES'), ('MS', 'MURES'), ('NT', 'NEAMT'), ('OT', 'OLT'), ('PH', 'PRAHOVA'), ('SB', 'SIBIU'), ('SJ', 'SALAJ'), ('SM', 'SATU'), ('SV', 'SUCEAVA'), ('TL', 'TULCEA'), ('TM', 'TIMIS'), ('TR', 'TELEORMAN'), ('VL', 'VALCEA'), ('VN', 'VRANCEA'), ('VS', 'VASLUI')]\n"
     ]
    }
   ],
   "source": [
    "raw = [(\"AB\",\"Alba\"),\n",
    "(\"AG\",\"Argeș\"),\n",
    "(\"AR\",\"Arad\"),\n",
    "(\"B\",\"București\"),\n",
    "(\"BC\",\"Bacău\"),\n",
    "(\"BH\",\"Bihor\"),\n",
    "(\"BN\",\"Bistrița-Năsăud\"),\n",
    "(\"BR\",\"Brăila\"),\n",
    "(\"BT\",\"Botoșani\"),\n",
    "(\"BV\",\"Brașov\"),\n",
    "(\"BZ\",\"Buzău\"),\n",
    "(\"CJ\",\"Cluj\"),\n",
    "(\"CL\",\"Călărași\"),\n",
    "(\"CS\",\"Caraș-Severin\"),\n",
    "(\"CT\",\"Constanța\"),\n",
    "(\"CV\",\"Covasna\"),\n",
    "(\"DB\",\"Dâmbovița\"),\n",
    "(\"DJ\",\"Dolj\"),\n",
    "(\"GJ\",\"Gorj\"),\n",
    "(\"GL\",\"Galați\"),\n",
    "(\"GR\",\"Giurgiu\"),\n",
    "(\"HD\",\"Hunedoara\"),\n",
    "(\"HR\",\"Harghita\"),\n",
    "(\"IF\",\"Ilfov\"),\n",
    "(\"IL\",\"Ialomița\"),\n",
    "(\"IS\",\"Iași\"),\n",
    "(\"MH\",\"Mehedinți\"),\n",
    "(\"MM\",\"Maramureș\"),\n",
    "(\"MS\",\"Mureș\"),\n",
    "(\"NT\",\"Neamț\"),\n",
    "(\"OT\",\"Olt\"),\n",
    "(\"PH\",\"Prahova\"),\n",
    "(\"SB\",\"Sibiu\"),\n",
    "(\"SJ\",\"Sălaj\"),\n",
    "(\"SM\",\"Satu-Mare\"),\n",
    "(\"SV\",\"Suceava\"),\n",
    "(\"TL\",\"Tulcea\"),\n",
    "(\"TM\",\"Timiș\"),\n",
    "(\"TR\",\"Teleorman\"),\n",
    "(\"VL\",\"Vâlcea\"),\n",
    "(\"VN\",\"Vrancea\"),\n",
    "(\"VS\",\"Vaslui\"),\n",
    "]\n",
    "\n",
    "for i in range(len(raw)):\n",
    "    x = raw[i][1]\n",
    "    x = x.upper()\n",
    "    x = x.split(\"-\")[0]\n",
    "    x = clear_diacritics(x)\n",
    "    raw[i] = (raw[i][0], x)\n",
    "\n",
    "    for j in range(i):\n",
    "        if raw[i][1] in raw[j][1] or raw[j][1] in raw[i][1]:\n",
    "            print(raw[i], raw[j])\n",
    "\n",
    "print(raw)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
